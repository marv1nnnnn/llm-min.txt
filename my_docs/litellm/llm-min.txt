S:LiteLLM;V:2025|O:K~LLM_Gateway,Unified_API,LLM_Orchestration,Cost_Tracking,Logging,Load_Balancing,Routing,Fallbacks,Caching,Observability;P~OpenAI_Compatibility,Extensibility,Reliability,Security,Cost_Management,Vendor_Agnostic|I:C~pip install litellm;C~pip install 'litellm[proxy]';C~docker pull ghcr.io/berriai/litellm:main-latest;P~Postgres_DB,Master_Key,Environment_Variables|C:M~Authentication,Logging,Load_Balancing,Rate_Limiting,Caching,Guardrails,Secret_Management,Plugins;O~config.yaml,litellm_config.yaml,docker/Dockerfile.non_root,docker/Dockerfile.database,custom_callbacks.py,custom_auth.py,mydata.jsonl,openai_batch_completions.jsonl,azure_batch_completions.jsonl;E~OPENAI_API_KEY,ANTHROPIC_API_KEY,AZURE_API_KEY,AZURE_API_BASE,AZURE_API_VERSION,VERTEXAI_PROJECT,VERTEXAI_LOCATION,NVIDIA_NIM_API_KEY,NVIDIA_NIM_API_BASE,HUGGINGFACE_API_KEY,OPENROUTER_API_KEY,VERTEX_PROJECT,VERTEX_LOCATION,LUNARY_PUBLIC_KEY,HELICONE_API_KEY,LANGFUSE_PUBLIC_KEY,LANGFUSE_SECRET_KEY,LANGFUSE_HOST,DATABASE_URL,LITELLM_MASTER_KEY,OTEL_TRACER_NAME,OTEL_SERVICE_NAME,OTEL_EXPORTER,OTEL_ENDPOINT,OTEL_HEADERS,GCS_BUCKET_NAME,GCS_PATH_SERVICE_ACCOUNT,GCS_PUBSUB_TOPIC_ID,GCS_PUBSUB_PROJECT_ID,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_REGION_NAME,AZURE_STORAGE_ACCOUNT_NAME,AZURE_STORAGE_FILE_SYSTEM,AZURE_STORAGE_ACCOUNT_KEY,AZURE_STORAGE_TENANT_ID,AZURE_STORAGE_CLIENT_ID,AZURE_STORAGE_CLIENT_SECRET,DD_API_KEY,DD_SITE,DD_ENV,DD_SERVICE,DD_SOURCE,DD_VERSION,HOSTNAME,POD_NAME,PROMPTLAYER_API_KEY,WANDB_API_KEY,SLACK_WEBHOOK_URL,ATHINA_API_KEY,ATHINA_BASE_URL,GREENSCALE_API_KEY,GREENSCALE_ENDPOINT,SUPABASE_URL,SUPABASE_KEY,LAGO_API_BASE,LAGO_API_KEY,LAGO_API_EVENT_CODE,OPENMETER_API_ENDPOINT,OPENMETER_API_KEY,SENTRY_DSN,BRAINTRUST_API_KEY,LITERAL_API_KEY,LITERAL_BATCH_SIZE,LOGFIRE_TOKEN,PHOENIX_API_KEY,PHOENIX_COLLECTOR_HTTP_ENDPOINT,QDRANT_API_BASE,QDRANT_API_KEY,REDIS_HOST,REDIS_PORT,REDIS_PASSWORD,LITELLM_LOCAL_MODEL_COST_MAP,SSL_VERIFY,SSL_SECURITY_LEVEL,SSL_CERTIFICATE,PROXY_BASE_URL,DEFAULT_VERTEXAI_PROJECT,DEFAULT_VERTEXAI_LOCATION,DEFAULT_GOOGLE_APPLICATION_CREDENTIALS,HOSTED_VLLM_API_BASE,MISTRAL_API_KEY,ANYSCALE_API_KEY,AZURE_AI_API_KEY,AZURE_AI_API_BASE,AI21_API_KEY,ALEPHALPHA_API_KEY,AZURE_AD_TOKEN,AZURE_TENANT_ID,AZURE_CLIENT_ID,AZURE_CLIENT_SECRET,AZURE_USERNAME,AZURE_PASSWORD,VERTEXAI_PROJECT,VERTEXAI_LOCATION,PALM_API_KEY,REPLICATE_API_KEY,COHERE_API_KEY,NVIDIA_NIM_API_KEY,NVIDIA_NIM_API_BASE,HUGGINGFACE_API_KEY,OPENROUTER_API_KEY,VOYAGE_API_KEY,JINA_API_KEY,PREDIBASE_API_KEY,IBM_WATSONX_API_KEY,IBM_WATSONX_PROJECT_ID,DATABRICKS_API_KEY,DATABRICKS_API_BASE,FIREWORKS_AI_API_KEY,VLLM_API_BASE,XINFERENCE_API_BASE,CLOUDFARE_ACCOUNT_ID,CLOUDFARE_API_KEY,DEEPINFRA_API_KEY,SAMBANOVA_API_KEY,SNOWFLAKE_API_KEY,SNOWFLAKE_ACCOUNT_ID,SNOWFLAKE_WAREHOUSE|A:completion(model~str,messages~list,timeout~float=)>ModelResponse,E~OpenAIError,APITimeoutError;acompletion(model~str,messages~list,timeout~float=)*>ModelResponse,E~OpenAIError,APITimeoutError;embedding(model~str,input~str|list)>EmbeddingResponse,E~OpenAIError;aembedding(model~str,input~str|list)*>EmbeddingResponse,E~OpenAIError;moderation(input~str|list,model~str)>object,E~OpenAIError;image_generation(prompt~str,model~str)>object,E~OpenAIError;aimage_generation(prompt~str,model~str)*>object,E~OpenAIError;transcription(model~str,file)>object,E~OpenAIError;atranscription(model~str,file)*>object,E~OpenAIError;speech(model~str,voice~str,input~str)>object,E~OpenAIError;rerank(model~str,query~str,documents~list)>object,E~OpenAIError;batch_completion(model~str,messages~list)>list,E~OpenAIError;batch_completion_models(models~list,messages~list)>ModelResponse,E~OpenAIError;batch_completion_models_all_responses(models~list,messages~list)>list,E~OpenAIError;create_assistants(custom_llm_provider~str,model~str,instructions~str,name~str,tools~list)>object;acreate_assistants(custom_llm_provider~str,model~str,instructions~str,name~str,tools~list)*>object;get_assistants(custom_llm_provider~str)>object;aget_assistants(custom_llm_provider~str)*>object;create_thread(custom_llm_provider~str,messages~list=())>object;acreate_thread(custom_llm_provider~str,messages~list=())*>object;get_thread(custom_llm_provider~str,thread_id~str)>object;aget_thread(custom_llm_provider~str,thread_id~str)*>object;add_message(thread_id~str,custom_llm_provider~str,role~str,content~str)>object;a_add_message(thread_id~str,custom_llm_provider~str,role~str,content~str)*>object;run_thread(custom_llm_provider~str,thread_id~str,assistant_id~str)>object;arun_thread(custom_llm_provider~str,thread_id~str,assistant_id~str)*>object;run_thread_stream(custom_llm_provider~str,thread_id~str,assistant_id~str,message~dict)>AssistantEventHandler;acreate_file(file,purpose~str,custom_llm_provider~str)*>object;alist_files(custom_llm_provider~str)*>object;aretrieve_file(file_id~str,custom_llm_provider~str)*>object;adelete_file(file_id~str,custom_llm_provider~str)*>object;afile_content(file_id~str,custom_llm_provider~str)*>object;acreate_batch(completion_window~str,endpoint~str,input_file_id~str,custom_llm_provider~str)*>object!E;aretrieve_batch(batch_id~str,custom_llm_provider~str)*>object!E;list_batches(custom_llm_provider~str)*>object!E;responses(model~str)*>object!B;check_valid_key(model~str,api_key)>bool;get_valid_models()>list;validate_environment(model~str)>object;encode(model~str,text~str)>list;decode(model~str,tokens~list)>str;token_counter(model~str,messages~list)>int;create_pretrained_tokenizer(tokenizer_name~str)>object;create_tokenizer(json_str~str)>object;cost_per_token(model~str,prompt_tokens~int,completion_tokens~int)>tuple;completion_cost(completion_response~object)>float;get_max_tokens(model~str)>int;register_model(model_cost~dict|str);supports_function_calling(model~str)>bool;supports_parallel_function_calling(model~str)>bool;supports_audio_output(model~str)>bool;supports_audio_input(model~str)>bool;supports_pdf_input(model~str)>bool;supports_vision(model~str)>bool;supports_web_search(model~str)>bool;supports_response_schema(model~str)>bool;trim_messages(messages~list,model~str=,max_tokens~int=,trim_ratio~float=)>list;stream_chunk_builder(chunks~list,messages~list=)>object;function_to_dict(func)>dict;modify_integration(integration_name~str,params~dict);register_prompt_template(model~str,roles~dict=,initial_prompt_value~str=,final_prompt_value~str=,bos_token~str=,eos_token~str=);enable_cache();disable_cache();update_cache();_turn_on_debug();callbacks~list;input_callback~list;success_callback~list;failure_callback~list;REPEATED_STREAMING_CHUNK_LIMIT~int=100;json_logs~bool;log_raw_request_response~bool;return_response_headers~bool;add_function_to_prompt~bool;drop_params~bool;enable_json_schema_validation~bool;max_budget~float;_current_cost~float;model_alias_map~dict;ssl_verify~bool;ssl_security_level~int;ssl_certificate~str;api_key~str;api_base~str;api_version~str;organization~str;BudgetManager(project_name~str,client_type~str=local,api_base~str=)(create_budget(total_budget~float,user~str,duration~str);projected_cost(model~str,messages~list,user~str);get_total_budget(user~str)>float;update_cost(completion_obj~ModelResponse,user~str);get_current_cost(user~str)>float;get_model_cost(user~str);is_valid_user(user~str)>bool;get_users();reset_cost(user~str);reset_on_duration(user~str);update_budget_all_users();save_data());Router(model_list~list=,redis_host~str=,redis_password~str=,redis_port~str=,set_verbose~bool=,debug_level~str=,timeout~int=,num_retries~int=,retry_after~int=,disable_cooldowns~bool=True,allowed_fails~int=3,cooldown_time~int=5,enable_pre_call_checks~bool=,cache_responses~bool=,caching_groups~list=,redis_url~str=,cache_kwargs~dict=,default_max_parallel_requests~int=,routing_strategy~str=simple-shuffle,routing_strategy_args~dict=,alerting_config~AlertingConfig=,router_general_settings~RouterGeneralSettings=)(completion(model~str,messages~list)>ModelResponse;acompletion(model~str,messages~list)*>ModelResponse;embedding(model~str,input~str|list)>EmbeddingResponse;aembedding(model~str,input~str|list)*>EmbeddingResponse;text_completion(model~str,prompt~str)>object;atext_completion(model~str,prompt~str)*>object;image_generation(prompt~str,model~str=)>object;aimage_generation(prompt~str,model~str=)*>object;set_custom_routing_strategy(strategy~object));integrations.custom_logger#CustomLogger()(log_pre_api_call(model,messages,kwargs);log_post_api_call(kwargs,response_obj,start_time,end_time);log_success_event(kwargs,response_obj,start_time,end_time);log_failure_event(kwargs,response_obj,start_time,end_time)*;async_log_success_event(kwargs,response_obj,start_time,end_time)*;async_log_failure_event(kwargs,response_obj,start_time,end_time)*;async_logging_hook(kwargs~dict,result,call_type~str)*>tuple;logging_hook(kwargs~dict,result,call_type~str)>tuple);caching.caching#Cache(type~str=local,supported_call_types~list=completion,acompletion,embedding,aembedding,atranscription,transcription,ttl~float=,default_in_memory_ttl~float=,host~str=,port~str=,password~str=,namespace~str=,default_in_redis_ttl~float=,redis_flush_size=,similarity_threshold~float=,redis_semantic_cache_embedding_model~str=text-embedding-ada-002,redis_semantic_cache_index_name~str=,s3_bucket_name~str=,s3_region_name~str=,s3_api_version~str=,s3_path~str=,s3_use_ssl~bool=True,s3_verify=,s3_endpoint_url~str=,s3_aws_access_key_id~str=,s3_aws_secret_access_key~str=,s3_aws_session_token~str=,s3_config=,disk_cache_dir=,qdrant_api_base~str=,qdrant_api_key~str=,qdrant_collection_name~str=,qdrant_quantization_config~str=,qdrant_semantic_cache_embedding_model~str=text-embedding-ada-002)(T~get_cache_key;T~add_cache;T~get_cache);fine_tuning#(jobs.create(model~str,training_file~str)>object!E;jobs.cancel(fine_tuning_job_id~str)>object!E;jobs.list()>object!E);proxy_cli#(proxy(config~str=,port~int=4000,detailed_debug~bool=));experimental_mcp_client#(load_mcp_tools(session~object,format~str=mcp)*>list;call_openai_tool(session~object,openai_tool~dict)*>object!E)|D:ModelResponse();EmbeddingResponse();Usage(prompt_tokens~int,completion_tokens~int,total_tokens~int);Choices();Message(role~str,content~str|list=);ChatCompletionMessageToolCall(id~str,function~Function,type~str);Function(name~str,arguments~str);PromptTokensDetailsWrapper();GenericBudgetInfo(budget_limit~float,time_period~str);RetryPolicy();AllowedFailsPolicy();AlertingConfig();RouterGeneralSettings();StandardKeyGenerationConfig();TeamUIKeyGenerationConfig();PersonalUIKeyGenerationConfig();LitellmUserRoles(str,enum.Enum);CustomLogger();Cache();AssistantEventHandler();GenerateKeyRequest();StandardLoggingPayload();Assistant();Thread();Run();FileObject();BatchObject();EmbeddingData();ModerationResponse();ModerationResult();CategoryScores();CompletionUsageDetails();PromptUsageDetails();FunctionDefinition();ToolDefinition();ImageURL();ImageData();InputAudioData();DocumentData();Citation();ToolUseContent();TextInputContent();ImageInputContent();AudioInputContent();DocumentInputContent();ToolOutputContent();TextOutputContent();ImageOutputContent();AudioOutputContent();DocumentOutputContent();ToolOutputContent();ThinkingContent();RedactedThinkingContent();UnsupportedParamsError(status_code~int,message~str,llm_provider~str);ContextWindowExceededError(status_code~int,message~str,llm_provider~str);ContentPolicyViolationError(status_code~int,message~str,llm_provider~str);InvalidRequestError(status_code~int,message~str,llm_provider~str)!D;AuthenticationError(status_code~int,message~str,llm_provider~str);PermissionDeniedError(status_code~int,message~str,llm_provider~str);NotFoundError(status_code~int,message~str,llm_provider~str);Timeout(status_code~int,message~str,llm_provider~str);UnprocessableEntityError(status_code~int,message~str,llm_provider~str);RateLimitError(status_code~int,message~str,llm_provider~str);APIConnectionError(status_code~int,message~str,llm_provider~str);APIError(status_code~int,message~str,llm_provider~str);ServiceUnavailableError(status_code~int,message~str,llm_provider~str);InternalServerError(status_code~int,message~str,llm_provider~str);APIResponseValidationError(status_code~int,message~str,llm_provider~str);BudgetExceededError(status_code~int,message~str,llm_provider~str);JSONSchemaValidationError(status_code~int,message~str,llm_provider~str);MockException(status_code~int,message~str,llm_provider~str);OpenAIError(status_code~int,message~str,llm_provider~str)!D|U:W:Basic_Completion_Call(completion)->print;W:Streaming_Completion_Call(completion->loop_chunk)->print;W:Async_Completion_Call(acompletion)*>print;W:Async_Streaming_Completion_Call(acompletion->loop_chunk)*>print;W:Retry_Failed_Request(completion->retry);W:Fallback_Model(completion->fallback->completion);W:Log_Input_Output(completion->callback);W:Proxy_Quickstart(pip install->start proxy->curl/sdk call);W:Generate_Virtual_Key(setup db->start proxy->curl key generate);W:Proxy_Load_Balancing(setup config->start proxy->curl call);W:Router_Load_Balancing(init router->acompletion);W:SDK_Latency_Load_Test(asyncio run loadtest_fn);W:Router_Multi_Instance_Load_Test(asyncio run parent_fn);W:Proxy_Multi_Instance_Load_Test(asyncio run parent_fn);W:SDK_Mock_Completion(completion mock_response)->print/assert;W:SDK_User_Budget_Management(init BudgetManager->create budget->check budget->completion->update cost);W:SDK_Function_Calling(completion tools auto)->parse tool calls->completion tool result;W:Proxy_Function_Calling(curl/sdk call tools auto);W:SDK_Image_Generation(image_generation)->print;W:Proxy_Image_Generation(curl/sdk call);W:SDK_Embeddings(embedding)->print;W:Proxy_Embeddings(curl/sdk call);W:SDK_Moderation(moderation)->print;W:Proxy_Moderation(curl/sdk call);W:SDK_Audio_Transcription(transcription)->print;W:Proxy_Audio_Transcription(curl/sdk call);W:SDK_Audio_Speech(speech)->stream_to_file;W:SDK_Vision(completion vision_messages)->print;W:Proxy_Vision(curl/sdk call);W:SDK_PDF_Input(completion file_messages)->print;W:Proxy_PDF_Input(curl/sdk call);W:SDK_Web_Search(completion web_search_options)->print;W:Proxy_Web_Search(curl/sdk call);W:SDK_Structured_Outputs(completion response_format)->print;W:Proxy_Structured_Outputs(curl/sdk call);W:SDK_Custom_Callback(set callback->completion)->print;W:SDK_Scrub_Logged_Data(set callback->completion)->log;W:Proxy_Raw_Log_Request(curl/sdk call)->log;W:SDK_API_Keys_Base_Version(completion api_key/base/version);W:SDK_Token_Usage_Cost(completion->completion_cost);W:SDK_Catch_OpenAI_Error(try completion except OpenAIError);W:SDK_Catch_Streaming_Error(try completion stream except OpenAIError)|F:Unified_API,100+_LLM_Support,OpenAI_Compatibility,Load_Balancing,Routing,Fallbacks,Retries,Cost_Tracking,Spend_Management,Budgets,Rate_Limits,Virtual_Keys,Model_Aliases,Logging,Observability,Streaming,Async,Exception_Mapping,Prompt_Management!B,Vision,Audio,PDF_Input,Web_Search,Structured_Outputs,Function_Calling,Batching,Assistants,Files,Fine-tuning!E,Responses_API!B,Realtime,Custom_Pricing,Caching,Secret_Managers,Plugins,Guardrails!B,Authentication,RBAC,Data_Privacy,Data_Retention,Benchmarks,Provider-specific_Params,Dropping_Unsupported_Params,Prompt_Formatting,Trimming_Input|X:PIP,Docker,CLI,Python_SDK,Proxy_Server,Self-hosted,Cloud,Kubernetes,AWS,Azure,GCP,HuggingFace,Replicate,TogetherAI,Ollama,AI21,AlephAlpha,Anyscale,Baseten,Cerebras,Cloudflare,Cohere,Custom_API,Databricks,DeepInfra,Deepgram,Deepseek,Fireworks_AI,FriendliAI,Galadriel,Github,Google_AI_Studio,Groq,Helicone,Humanloop,IBM_Watsonx,Infinity,Jina_AI,Lago,Langfuse,Langsmith,Literal_AI,LM_Studio,Logfire,Lunary,Mistral,MLflow,Nvidia_NIM,NLP_Cloud,OpenMeter,OpenRouter,Petals,Phoenix_OSS,Predibase,Promptlayer,Sambanova,Sagemaker,Sentry,Snowflake,Supabase,Telemetry,Topaz,Traceloop,Triton,VertexAI,Volcano_Engine,Voyage_AI,Weights_&_Biases,Xinference,Yival|Z:^Ipip install litellm^;^Ifrom litellm import completion\nimport os\nos.environ["OPENAI_API_KEY"] = "your-api-key"\nresponse = completion(\n model="openai/gpt-4o",\n messages=[{ "content": "Hello, how are you?","role": "user"}]\n)^;^Ifrom litellm import completion\nimport os\nos.environ["OPENAI_API_KEY"] = "your-api-key"\nresponse = completion(\n model="openai/gpt-4o",\n messages=[{ "content": "Hello, how are you?","role": "user"}],\n stream=True,\n)^;^Ifrom openai.error import OpenAIError\nfrom litellm import completion\nos.environ["ANTHROPIC_API_KEY"] = "bad-key"\ntry:\n completion(model="claude-instant-1", messages=[{"role": "user", "content": "Hey, how's it going?"}])\nexcept OpenAIError as e:\n print(e)^;^Ipip install 'litellm[proxy]'^;^I$ litellm --model huggingface/bigcode/starcoder\n#INFO: Proxy running on http://0.0.0.0:4000^;^Imodel_list:\n - model_name: gpt-3.5-turbo\n  litellm_params:\n   model: azure/<your-azure-model-deployment>\n   api_base: os.environ/AZURE_API_BASE\n   api_key: os.environ/AZURE_API_KEY\n   api_version: "2023-07-01-preview"^;^Idocker run \\\n  -v $(pwd)/litellm_config.yaml:/app/config.yaml \\\n  -e AZURE_API_KEY=d6*********** \\\n  -e AZURE_API_BASE=https://openai-***********/ \\\n  -p 4000:4000 \\\n  ghcr.io/berriai/litellm:main-latest \\\n  --config /app/config.yaml --detailed_debug^;^Iimport openai\nclient = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000")\nresponse = client.chat.completions.create(model="gpt-3.5-turbo", messages = [\n  {\n    "role": "user",\n    "content": "this is a test request, write a short poem"\n  }\n])\nprint(response)^;^Icurl 'http://0.0.0.0:4000/key/generate' \\\n--header 'Authorization: Bearer <your-master-key>' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{"models": ["gpt-3.5-turbo", "gpt-4"], "metadata": {"user": "ishaan@berri.ai"}}'^;^Icurl 'http://0.0.0.0:4000/key/info?key=<user-key>' \\\n   -X GET \\\n   -H 'Authorization: Bearer <your-master-key>'^;^Icurl --location 'http://localhost:4000/user/new' \\\n--header 'Authorization: Bearer <your-master-key>' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{user_email: "krrish@berri.ai"}'^;^Icurl --location 'http://localhost:4000/team/new' \\\n--header 'Authorization: Bearer <your-master-key>' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{"team_alias": "my-awesome-team"}'^;^Iimport litellm\ndef track_cost_callback(kwargs,completion_response,start_time,end_time):\n try:\n  response_cost = kwargs.get("response_cost", 0)\n  print("streaming response_cost", response_cost)\n except:\n  pass\nlitellm.success_callback = [track_cost_callback]\nresponse = completion(\n  model="gpt-3.5-turbo",\n  messages=[{\n      "role": "user",\n      "content": "Hi ðŸ‘‹ - i'm openai"\n    }],\n  stream=True\n)^;^Icurl -X POST 'http://0.0.0.0:4000/chat/completions' \\\n-H 'Content-Type: application/json' \\\n-H 'Authorization: Bearer sk-1234' \\\n-d '{ \\\n  "model": "gpt-3.5-turbo", \\\n  "messages": [ \\\n   { \\\n    "role": "system", \\\n    "content": "You are a helpful math tutor. Guide the user through the solution step by step." \\\n   }, \\\n   { \\\n    "role": "user", \\\n    "content": "how can I solve 8x + 7 = -23" \\\n   } \\\n  ] \\\n}'^;